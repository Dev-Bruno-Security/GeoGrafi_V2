"""
Aplica√ß√£o Streamlit simplificada para processamento de CEPs
- Apenas valida CEPs (n√£o busca coordenadas)
- Muito mais r√°pida (0.1s por CEP vs 2.5s com coordenadas)
"""

import streamlit as st
import pandas as pd
import tempfile
import logging
from pathlib import Path
from io import BytesIO
from modules.csv_processor import CSVProcessor
from modules.logging_config import setup_logging

# Importa√ß√£o condicional do plotly
try:
    import plotly.graph_objects as go
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

# Configura√ß√£o
st.set_page_config(page_title="GeoGrafi - Valida√ß√£o CEP", layout="wide")
setup_logging(level='INFO')
logger = logging.getLogger(__name__)

# Estado
if 'uploaded_file' not in st.session_state:
    st.session_state.uploaded_file = None
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'processing_complete' not in st.session_state:
    st.session_state.processing_complete = False

st.title("üåç GeoGrafi - Valida√ß√£o e Corre√ß√£o de CEPs")

with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    st.info("""
    **Modo R√°pido com Corre√ß√£o**
    
    ‚úÖ Valida CEPs via ViaCEP  
    ‚úÖ Corrige endere√ßos  
    ‚úÖ Retorna logradouro, bairro, cidade, UF
    
    ‚ö° ~0.15s por CEP (com rate limiting)
    
    **Vers√£o com coordenadas dispon√≠vel em `app_geo.py`**
    """)

# Upload de arquivo
st.header("1Ô∏è‚É£ Upload do Arquivo")
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader(
        "Selecione um arquivo CSV",
        type=['csv'],
        accept_multiple_files=False
    )

with col2:
    if uploaded_file:
        file_size_mb = uploaded_file.size / (1024 * 1024)
        st.metric("Tamanho", f"{file_size_mb:.1f} MB")

# Processamento
if uploaded_file:
    st.session_state.uploaded_file = uploaded_file
    
    st.header("2Ô∏è‚É£ Processamento")
    
    # Configura√ß√µes de processamento
    col1, col2, col3 = st.columns(3)
    with col1:
        chunk_size = st.number_input("Tamanho do chunk", min_value=100, max_value=5000, value=1000, step=100)
    
    with col2:
        encoding = st.selectbox(
            "Encoding",
            ["utf-8", "iso-8859-1", "cp1252", "auto-detect"],
            index=0
        )
    
    with col3:
        delimiter = st.selectbox(
            "Delimitador",
            [",", ";", "|", "\t", "auto-detect"],
            index=0
        )
    
    # Preview do arquivo
    if uploaded_file:
        with st.expander("üëÅÔ∏è Visualizar primeiras linhas do arquivo", expanded=False):
            try:
                # L√™ apenas as primeiras linhas para preview
                preview_df = pd.read_csv(uploaded_file, nrows=5, dtype=str)
                st.write(f"**Colunas detectadas:** {', '.join([f'`{col}`' for col in preview_df.columns])}")
                st.dataframe(preview_df)
                
                # Verifica se tem coluna de CEP
                has_cep = any('cep' in col.lower() or 'postal' in col.lower() or 'zip' in col.lower() 
                             for col in preview_df.columns)
                
                if has_cep:
                    st.success("‚úÖ Coluna de CEP detectada!")
                else:
                    st.warning("‚ö†Ô∏è Nenhuma coluna de CEP detectada. Certifique-se de ter uma coluna chamada 'cep' ou 'CEP'.")
                
                # Reset file pointer
                uploaded_file.seek(0)
            except Exception as e:
                st.error(f"Erro ao ler preview: {e}")
                uploaded_file.seek(0)
    
    # Bot√£o de processar
    if st.button("‚ñ∂Ô∏è Processar Arquivo", key="process_btn"):
        with st.spinner("‚è≥ Processando arquivo..."):
            try:
                # Salva arquivo tempor√°rio
                with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp:
                    tmp.write(uploaded_file.getbuffer())
                    tmp_path = tmp.name
                
                logger.info(f"Arquivo tempor√°rio: {tmp_path}")
                
                # Cria processador (SEM busca de coordenadas = R√ÅPIDO)
                processor = CSVProcessor(
                    chunk_size=chunk_size,
                    use_cache=True,
                    fetch_coordinates=False  # üîë DESABILITADO = R√ÅPIDO
                )
                
                # Processa
                result = processor.process_file(tmp_path)
                
                st.session_state.processed_data = result
                st.session_state.processing_complete = True
                
                logger.info(f"Processamento completo: {len(result)} linhas")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao processar: {str(e)}")
                logger.exception("Erro no processamento")

# Exibe resultados
if st.session_state.processing_complete and st.session_state.processed_data is not None:
    df = st.session_state.processed_data
    
    st.header("3Ô∏è‚É£ Resultados")
    
    # Estat√≠sticas
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìä Total de Linhas", len(df))
    with col2:
        valid_count = (df['cep_valido'] == True).sum() if 'cep_valido' in df.columns else 0
        st.metric("‚úÖ CEPs V√°lidos", valid_count)
    with col3:
        invalid_count = (df['cep_valido'] == False).sum() if 'cep_valido' in df.columns else 0
        st.metric("‚ùå CEPs Inv√°lidos", invalid_count)
    with col4:
        if 'cep_valido' in df.columns and len(df) > 0:
            taxa = (valid_count / len(df) * 100)
            st.metric("üìà Taxa de Sucesso", f"{taxa:.1f}%")
    
    # Visualiza√ß√£o dos dados
    st.subheader("üìã Dados Processados")
    
    # Seleciona colunas importantes para exibir
    display_cols = []
    for col in ['cep_original', 'cep_corrigido', 'cep_valido', 'logradouro', 'bairro', 'cidade', 'uf']:
        if col in df.columns:
            display_cols.append(col)
    
    # Adiciona outras colunas que n√£o s√£o de processamento
    for col in df.columns:
        if col not in display_cols and col not in ['latitude', 'longitude']:
            display_cols.append(col)
    
    if display_cols:
        st.dataframe(df[display_cols], width='stretch')
    else:
        st.dataframe(df, width='stretch')
    
    # Download
    st.subheader("üíæ Download")
    
    col1, col2 = st.columns(2)
    
    # Nome do arquivo
    output_name = "resultado"
    if st.session_state.uploaded_file:
        output_name = f"resultado_{st.session_state.uploaded_file.name}"
    
    with col1:
        csv_data = df.to_csv(index=False, encoding='utf-8')
        st.download_button(
            label="üì• Baixar CSV",
            data=csv_data,
            file_name=output_name if output_name.endswith('.csv') else output_name + '.csv',
            mime="text/csv"
        )
    
    with col2:
        # Cria buffer em mem√≥ria para o Excel
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Resultado')
        buffer.seek(0)
        
        excel_name = output_name.replace('.csv', '.xlsx') if '.csv' in output_name else output_name + '.xlsx'
        st.download_button(
            label="üì• Baixar Excel",
            data=buffer,
            file_name=excel_name,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    
    # Filtros
    st.subheader("üîç An√°lise")
    
    tab1, tab2, tab3 = st.tabs(["‚úÖ CEPs V√°lidos", "‚ùå CEPs Inv√°lidos", "üìä Estat√≠sticas"])
    
    with tab1:
        if 'cep_valido' in df.columns:
            valid_df = df[df['cep_valido'] == True]
            st.write(f"**{len(valid_df)} CEPs v√°lidos encontrados**")
            
            # Mostra colunas relevantes
            cols_to_show = [c for c in ['cep_original', 'cep_corrigido', 'logradouro', 'bairro', 'cidade', 'uf'] if c in valid_df.columns]
            if cols_to_show:
                st.dataframe(valid_df[cols_to_show], width='stretch')
            else:
                st.dataframe(valid_df, width='stretch')
        else:
            st.info("Coluna 'cep_valido' n√£o encontrada")
    
    with tab2:
        if 'cep_valido' in df.columns:
            invalid_df = df[df['cep_valido'] == False]
            st.write(f"**{len(invalid_df)} CEPs inv√°lidos encontrados**")
            
            if len(invalid_df) > 0:
                st.warning("‚ö†Ô∏è Estes CEPs n√£o foram encontrados na base do ViaCEP. Verifique se est√£o corretos.")
                
                # Mostra CEPs inv√°lidos
                cols_to_show = [c for c in ['cep_original', 'cep_corrigido'] if c in invalid_df.columns]
                if cols_to_show:
                    st.dataframe(invalid_df[cols_to_show], width='stretch')
                else:
                    st.dataframe(invalid_df, width='stretch')
            else:
                st.success("üéâ Todos os CEPs s√£o v√°lidos!")
        else:
            st.info("Coluna 'cep_valido' n√£o encontrada")
    
    with tab3:
        st.write("**üìä Estat√≠sticas do Processamento:**")
        
        valid_count = (df['cep_valido'] == True).sum() if 'cep_valido' in df.columns else 0
        invalid_count = (df['cep_valido'] == False).sum() if 'cep_valido' in df.columns else 0
        total = len(df)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("üìä Total Processado", total)
            st.metric("‚úÖ CEPs V√°lidos", valid_count)
            st.metric("‚ùå CEPs Inv√°lidos", invalid_count)
        
        with col2:
            if total > 0:
                taxa_sucesso = (valid_count / total) * 100
                taxa_erro = (invalid_count / total) * 100
                
                st.metric("üìà Taxa de Sucesso", f"{taxa_sucesso:.1f}%")
                st.metric("üìâ Taxa de Erro", f"{taxa_erro:.1f}%")
                
                # Gr√°fico visual (se plotly dispon√≠vel)
                if PLOTLY_AVAILABLE:
                    fig = go.Figure(data=[go.Pie(
                        labels=['V√°lidos', 'Inv√°lidos'],
                        values=[valid_count, invalid_count],
                        marker=dict(colors=['#28a745', '#dc3545']),
                        hole=0.4
                    )])
                    
                    fig.update_layout(
                        title="Distribui√ß√£o de CEPs",
                        height=300
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    # Gr√°fico de barras simples sem plotly
                    st.bar_chart({'V√°lidos': valid_count, 'Inv√°lidos': invalid_count})
        
        # Resumo textual
        st.divider()
        st.write("**üìù Resumo:**")
        st.write(f"- De **{total}** CEPs processados:")
        st.write(f"  - ‚úÖ **{valid_count}** foram validados com sucesso")
        st.write(f"  - ‚ùå **{invalid_count}** n√£o foram encontrados na base do ViaCEP")
        
        if 'logradouro' in df.columns:
            with_address = df['logradouro'].notna().sum()
            st.write(f"  - üè† **{with_address}** possuem endere√ßo completo")


# Footer
st.divider()
st.caption("üöÄ GeoGrafi V2 - Valida√ß√£o e Corre√ß√£o de CEPs | Modo: R√°pido com ViaCEP")
